<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<!--     <meta name="viewport" content="width=device-width, initial-scale=1"> -->
    <meta name="google-site-verification" content="RRBnwYbS4fA-miRhlvTT9lm9uJrWSHPbv_-4PYUiH2M" />
    <!-- Swiper CSS -->
        <link rel="stylesheet" href="./swiper/css/swiper-bundle.min.css">

        <!-- Google tag (gtag.js) -->
        <script async="" src="./js"></script>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
        <script src="https://code.jquery.com/jquery-3.6.2.min.js" integrity="sha256-2krYZKh//PcchRtd+H+VyyQoZ/e3EcrkxhM8ycwASPA=" crossorigin="anonymous"></script>
        <script src="./swiper/js/reshadow.js"></script>
        <script src="./swiper/js/relight.js"></script>
        <script src="./swiper/js/move_light.js"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-XB3PR2Y1TQ');
        </script>
    <title>Zero-guideSeg</title>
    <link rel="stylesheet" href="assets/scripts/bulma.min.css">
    <style>
      .black-frame{
        height: 100%;
        background: #171617;
        width: 100%;
        display : flex;
        align-items : center;
        justify-content: center;
      }
      .card {
      margin: 10px;
      }

      .card .media-content .title,
      .card .media-content .subtitle {
        color: #4a4a4a;
      }

      .subtitle {
        margin-top: -0.8rem !important;
      }

      .card-footer {
        text-align: center;
      }

      h1.title {
        font-size: 30px;
        margin-bottom: 10px !important;
      }

      h1 {
        font-size: 25px;
        font-weight: bold;
      }
      .author {
        display: inline;
        margin: 15px;
        color: #3376cb;
      }
      .contrib {
        font-size: 12px;
      }
      .aff {
        margin-top: 20px;
        font-size: 18px;
      }.head_cap {
        margin-top: 10px;
        font-size: 18px;
      }
      .location {
        font-size: 16px;
      }

      .hero-body {
        padding: 20px;
      }

      .column {
        padding: 0px !important;
      }
      .subtitle {
        padding-top: 5px;
        font-size: 16px;
      }

      .hero {
        background-color: inherit !important;
      }
      
      @media only screen and (max-width: 600px) {
      .author {
        font-size: 12px;
      }
      .aff {
        font-size: 12px;
      }
      .location {
        font-size: 12px;
      }}
      
      .button-clipboard-tooltip{
        display: none;
        color:white;
        background: rgba(74,74,74,0.9);
        border-radius: 2px;
        padding: 0.5rem 1rem;
        margin-right: 1rem;
        text-overflow: ellipsis;
        white-space: pre;
    }

      body {
        background-color: #FAFAFA;
      }
    </style>
  </head>
  <body>
    <section class="hero is-light" style="">
      <div class="hero-body" style="padding-top: 50px;">
        <div class="container" style="text-align: center;margin-bottom:5px;">
          <h1 class="title">
            Zero-guidance Segmentation Using Zero Segment Labels
          </h1>
          
          <div class="author">Pitchaporn Rewatbowornwong*<sup>1</sup></div>
          <div class="author">Nattanat Chatthee*<sup>1</sup></div>
          <div class="author">Ekapol Chuangsuwanich<sup>2</sup></div>
          <div class="author"><a href="http://www.supasorn.com">Supasorn Suwajanakorn</a><sup>1</sup></div>
          <div class="columns"><div class="column"></div>

          <div class="column">
           <div class="aff">
            <p style="color: gray; --darkreader-inline-color:#988f81;" data-darkreader-inline-color="">
            VISTEC<sup>1</sup>
<!--               VISTEC - Vidyasirimedhi Institute of Science and Technology<sup>1</sup> -->
            </p>
          </div>
          <div class="location">
            <p style="color: gray; --darkreader-inline-color:#988f81;" data-darkreader-inline-color="">
            Rayong, Thailand
            </p>
          </div>
          </div><div class="column">
          <div class="aff">
            <p style="color: gray; --darkreader-inline-color:#988f81;" data-darkreader-inline-color="">
            Chulalongkorn University<sup>2</sup>
            </p>
          </div>
          <div class="location">
            <p style="color: gray; --darkreader-inline-color:#988f81;" data-darkreader-inline-color="">
            Bangkok, Thailand
            </p>
          </div></div>
          <div class="column"></div>
          </div>
          <div class="con">
            <p  style="font-size: 24px; margin-top:15px;">
<!--             CVPR 2021 (Oral) -->
<!--               Under review -->
            </p>
          </div>
          <div class="contrib">
            *Equal contribution
          </div>
        </div>
      </div>
    </section>
<!--     <section class="section" style="display : flex; align-items : center;justify-content: center;padding: 10px;">
    <div style="max-width:  900px;width: 900px;">
      <div style="position: relative;width: 100%;height: 0;padding-bottom: 56.25%;">
        <iframe height="506.25" width="900"
          style=" position: absolute;top: 0;left: 0;width: 100%;height: 100%;max-height: 100%; max-width: 100%;"
          src="https://www.youtube.com/embed/Jx49VwN7O0Q" frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
          allowfullscreen></iframe>
      </div>
    </div>
  </section> -->
      <center>
        <img src="assets/images/header-1.png" width="1000px" height="1000px">
        <div class="head_cap">
            <p style="color:gray;font-size: 14px;margin-bottom:0.5cm;">
            <b>Zero-guidance Segmentation</b> segments input images and generated text labels for all segments without any guidance or prompting. <br> 
            Our method produces these results using only pretrained networks with no fine-tuning or annotations 
            </p>
        </div>
      </center>
    <section class="hero">
      <div class="hero-body">
        <div class="container" style="max-width: 800px" >
          <h1 style="">Abstract</h1>
          <p  style="text-align: justify; font-size: 17px;margin-bottom:0.5cm;">
<!--             CLIP has enabled new and exciting joint vision-language applications, one of which is open-vocabulary 
            segmentation, which can locate any segment given an arbitrary text query. Our paper asks the next question: 
            can we discover semantic segments without user guidance in the form of text queries or predefined classes 
            and label them in natural language all automatically? We propose a novel problem <b> zero-guidance segmentation </b> 
            and the first baseline that leverages two pretrained generalist models, DINO and CLIP, to solve this problem 
            without any fine-tuning or segmentation dataset. The general idea is to first segment an image into small 
            over-segments, encode them into CLIP’s visual-language space, translate them into text labels, and merge 
            semantically similar segments together. The key challenge, however, is how to encode a visual segment into a 
            segment-specific embedding that balances global and local context information, both useful for recognition. 
            Our main contribution is a novel attention-masking technique that balances the two contexts by analyzing the 
            attention layers inside CLIP. We also introduce several metrics for the evaluation of this new task. With 
            CLIP’s innate knowledge, our method can precisely locate the Mona Lisa painting among a museum crowd. -->
            
            CLIP has enabled new and exciting joint vision-language applications, one of which is open-vocabulary 
            segmentation, which can locate any segment given an arbitrary text query. In our research, we ask whether it 
            is possible to discover semantic segments without any user guidance in the form of text queries or predefined 
            classes, and label them using natural language automatically? We propose a novel problem <b> zero-guidance segmentation </b> 
            and the first baseline that leverages two pre-trained generalist models, DINO and CLIP, to solve this problem 
            without any fine-tuning or segmentation dataset. The general idea is to first segment an image into small 
            over-segments, encode them into CLIP’s visual-language space, translate them into text labels, and merge 
            semantically similar segments together. The key challenge, however, is how to encode a visual segment into a 
            segment-specific embedding that balances global and local context information, both useful for recognition. 
            Our main contribution is a novel attention-masking technique that balances the two contexts by analyzing the 
            attention layers inside CLIP. We also introduce several metrics for the evaluation of this new task. With 
            CLIP’s innate knowledge, our method can precisely locate the Mona Lisa painting among a museum crowd.
          </p>
        </div>
      </div>
    </section>
    <section class="hero">
      <div class="hero-body">
        <div class="container" style="max-width: 800px" >
          <h1 style="">Our Pipeline</h1>
          <p  style="text-align: justify; font-size: 17px;margin-bottom:0.1cm;">
            Our method first segments an input image by clustering learned per-pixel features extracted from DINO. The 
            input image is then fed into CLIP’s image encoder. In this step, the produced segmentation masks are used to 
            modify CLIP’s attention to provide embeddings that are more focused to each segment. The resulting embeddings 
            are then used to optimize a trained language model to generate texts closest to these embeddings. Lastly, 
            segments with similar embeddings and text outputs are merged together to form more coherent segmentation results.
          </p>
        </div>
      </div>
    </section>
    <center>
        <img src="assets/images/pipeline.png" width="850px" height="850px">
      </center>
    <section class="hero is-light" style="">
      <div class="hero-body">
        <div class="container" style="text-align: center;margin-top:1cm;">
          <div class="columns">
            <div class="column"></div>
            <div class="column">
              <a href="https://arxiv.org/pdf/2103.04379.pdf" target="_blank">
                <div>
                  <img src="assets/images/paper.png" style=" box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.3); border-radius: 5px; padding: 5px;" width="40%" height="40%">
                </div>
                <p style="color:#3376cb;">Paper</p>
              </a>
            </div>
<!--             <div class="column">
              <a href="https://github.com/bryandlee/repurpose-gan/" target="_blank">
              <div>
                <img src="assets/video/bryandlee.gif" style=" box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.3); border-radius: 5px; padding: 5px;" width="72%" height="72%">
              </div>
              <p style="color:#3376cb;">Unofficial code with labelling tool by bryandlee</p>
                 </a>
            </div> -->
<!--             <div class="column">
              <div>
                <img src="assets/images/our_dataset.png">
              </div>
              Data [Soon]
            </div> -->
            <div class="column"></div>
          </div>
        </div>
      </div>
    </section>

    <section class="hero is-light" style="background-color:#FFFFFF;">
      <div class="hero-body">
        <div class="container" style="max-width:800px;margin-bottom:20px;">
          <h1>
            Zero-guidance Segmentation Results
          </h1>
        </div></div> 
      </section>
    <center>
        <img src="assets/images/results2.png" width="850px" height="850px">
        <img src="assets/images/results.png" width="850px" height="850px">
      </center>
  <section class="hero" style="padding-top:0px;">
    <div class="hero-body">
      <div class="container" style="max-width:900px;">
  <div class="card">
  <header class="card-header">
    <p class="card-header-title">
      BibTex
    </p>
    <a class="card-header-icon button-clipboard" style="border:0px; background: inherit;" data-clipboard-target="#bibtex-info" >
      <div class="button-clipboard-tooltip">Copied!</div>
      <span class="icon">
        <img src="assets/images/copy.svg" style="height: 20px;"/>
      </span>
    </a>
  </header>
    <div class="card-content">
<pre style="background-color:inherit;padding: 0px;" id="bibtex-info">@inproceedings{Rewatbowornwong2023ZeroGuideSeg, 
    author = {Rewatbowornwong, Pitchaporn and Chatthee, Nattanat and Chuangsuwanich, Ekapol and Suwajanakorn, Supasorn},
    title = {Zero-guidance Segmentation Using Zero Segment Labels},
    booktitle = {arXiv},
    year = {2023},
}</pre>
    </div></div></div></div>
    </section>
<!--     <section class="hero">
    <div class="hero-body">
      <div class="container" style="max-width:900px;">
        <div class=" col-max-width container">
          <h1 class="title shead">
            Another project from our lab 
          </h1>

          <a href="http://repurposegans.github.io/" target="_blank">
            <div class="card">
                <header class="card-header">
                  <p class="card-header-title">
                    Repurposing GANs for One-shot Semantic Part Segmentation
                  </p>
                  <p class="card-header-icon" aria-label="more options">
                    CVPR 2021 (Oral)
                  </p>
                </header>
                <div class="card-content">
                  <div class="content">
                    <img src="assets/images/reproposed_gan.png" />
                  </div>
                </div>
              </div>
          </a>
      </div>
     </div>
    </div>
  </section> -->
    <section class="hero">
      <div class="hero-body">
        <div class="container" style="width: 400px">
          <div class="columns" style="text-align: center;">
            <div class="column">
              <a href="https://vistec.ist/vision" target="_blank">Vision & Learning Lab</a>
            </div>
            <div class="column">
              <a href="https://www.vistec.ac.th/" target="_blank">VISTEC</a>
            </div>
          </div>
        </div>
      </div>
    </section>
     <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-QRZRM1ZZ9J"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-QRZRM1ZZ9J');
    </script>
     <script src="assets/scripts/clipboard.min.js"></script>
  <script>
    var clipboard = new ClipboardJS('.button-clipboard');
    function setTooltip(){
      var tooltip = document.querySelector('.button-clipboard-tooltip');
      tooltip.style.display = 'block';
    }
    function hideTooltip(){
      var tooltip = document.querySelector('.button-clipboard-tooltip');
      tooltip.style.display = 'none';
    }
    clipboard.on('success', function(e) {
      setTooltip(e.trigger, 'Copied!');
      setTimeout(function(){
        hideTooltip(e.trigger);
      }, 2000);
      
    });
    
  </script>
  </body>
</html>
